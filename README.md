## Table of Contents

- [OpenAI-Compatible Client for LM Studio](#openai-compatible-client-for-lm-studio)
- [What's new](#whats-new)
- [Install in 5 seconds](#install-in-5-seconds)
- [Full text search](#full-text-search)
- [Quick start](#quick-start)
- [Roadmap & bugs](#roadmap--bugs)
- [Project Support](#support)
- [Project Supporters](#project-supporters)
- [Links](#links)

# OpenAI-Compatible Client for LM Studio

Turn **LM Studio** into a cloud-ready powerhouse. Access local and cloud inference simultaneously in the same app!
This fork lets you chat with **Cerebras, Groq, OpenRouter, Claude, GPT-4o, Gemini-2.5, DeepSeek, Kimi-K2, GLM V4.5**—or any OpenAI-shaped endpoint—without ever leaving the comfy LM Studio UI.

## What’s new

- **Added support for reasoning effort and thinking for OpenAI and Anthropic compatible models** 
- Native OpenAI sampling knobs (temperature, top-p, frequency penalty, etc.) exposed in the GUI  
- Zero config: paste your API key, pick the model, start vibing  
- Keeps all local-model superpowers intact—switch between cloud and local on the fly
- Added custom system prompt support 

## Install in 5 seconds

1. Navigate to [LM Studio Hub](https://lmstudio.ai/gdmka/openai-compat-endpoint)
2. Hit **“Run in LM Studio”** on the plugin page   
<img width="168" height="34" alt="image" src="https://github.com/user-attachments/assets/3f0566de-6a43-41db-8edb-fb18b4e585d7" />

3. Done—plugin will be available in Chat view under Your Generators section
<img width="1362" height="278" alt="image" src="https://github.com/user-attachments/assets/e37b10e7-b101-4bc3-be5e-d5712e29c02f" />


## Full text search

Unlock the full power of productivity by instantly navigating between search terms with built-in full-text search across your chat history.

<img width="1795" height="1286" alt="image" src="https://github.com/user-attachments/assets/0e491a38-5481-40ec-a410-bee46447ead4" />



## Quick start

1. Grab an API key from your favorite provider (Cerebras, Groq, OpenRouter, Anthropic, OpenAI, etc.)  
2. In LM Studio → Chat → Your Generators load the plugin → hit Show Settings shortcut → pick Generators tab → paste key  
3. Type model name, select AI provider, tweak sampling, chat away!

<img width="1792" height="1083" alt="image" src="https://github.com/user-attachments/assets/2dfef5a0-0d26-411d-b1a3-f10188941f01" />


## Roadmap & bugs

Got feature requests or bugs?  
Drop them in the [Issues](https://github.com/gdmka/openai-compat-endpoint/issues) tab—every ticket gets love.

## Support

If you find this project helpful, consider buying me a coffee!  

<a href="https://www.buymeacoffee.com/gdmka" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" ></a>

## Project Supporters

[@jrdubbleu](https://github.com/jrdubbleu)


## Links

- Plugin Hub page: [https://lmstudio.ai/gdmka/openai-compat-endpoint](https://lmstudio.ai/gdmka/openai-compat-endpoint)
